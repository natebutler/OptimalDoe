---
title: "Introduction to optimalDoe"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to optimalDoe}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  fig.width = 7,
  fig.height = 4,
  collapse = TRUE,
  comment = "#>"
)
```
This vignette is intended for practitioners hoping to generate an optimal experimental design. This package implements the coordinate exchange algorithm to generate D and A optimal experimental designs. In addition to generating optimal experimental designs, this package also provides the user with tools to further analyze the generated experimental designs. This vignette is housed at https://github.com/natebutler/OptimalDoe, where you can install the package using the code below.

## Package Installation
```{r setup, comment = NA}
# devtools::install_github("natebutler/OptimalDoe")
library(optimalDoe)
```
## Generating Designs
Here is how you generate some optimal designs:
```{r, comment = NA, cache = TRUE}
set.seed(2187)
designs_d <- generate_designs(
  n = 10, k = 2, order = 1, criteria = "D",
  iterations = 20
)

designs_a <- generate_designs(
  n = 10, k = 2, order = 1, criteria = "A",
  iterations = 20
)
```
Above, we specify: 

* n - the number of experimental runs 
* k - the number of experimental factors  
* order - order of the model you want 
  + Enter 0 for a first order main effects model 
  + 1 for a first order model with 2 way interactions 
  + 2 for a second order model with 2 way interactions and squared main effects 
* criteria - the scoring criteria used to find the optimal design. Enter 
either 'A' or 'D' to score on A-criteria or D-criteria 
* iterations - the number of iterations you want the coordinate exchange algorithm to run 

The generate_designs function takes in the above parameters and runs the coordinate exchange algorithm to generate either A or D optimal experimental designs based on the user-specified criteria. It will generate designs with N runs and k factors with the intention of fitting the order of the model specified. The user will then specify the number of iterations and the coordinate exchange algorithm will run that number of times. It should be noted that Brad Jones and Peter Goos recommend running the coordinate exchange algorithm for at least 1000 iterations in their textbook "Optimal Design of Experiments: A Case Study Approach." 

```{r, comment = NA}
head(designs_d)

head(designs_a)
```
The generate_designs function returns an ordered list (by ascending optimality score) where the length is that of the iterations specified. Each element of that list is a list of length 2 where the first element is a locally optimal design matrix and the second is the associated optimality score associated with that matrix.

## Scoring Functions
While our generate_design function does score generated designs on the specified criteria, users may want to cross-compare scorings of the other criteria. They can do so with the following functions:
```{r, comment = NA}
# Pull out first design matrix of the list.
result_a <- designs_a[[1]][[1]]
result_d <- designs_d[[1]][[1]]

d_crit(design = result_a, order = 1)
a_crit(design = result_a, order = 1)
```
The d_crit function takes a design matrix and a specified order of model (same order as before) and expands the design matrix into the model matrix then calculates and returns the determinant of the inverse of the information matrix. 

The a_crit function takes a design matrix and a specified order of model (same order as before) and expands the design matrix into the model matrix then calculates and returns the trace of the inverse of the information matrix. 

### Singularity Check
Another function, singular_check, is called under the hood of the criteria functions. Its use is to check that the information matrix is not numerically singular. The threshold is machine epsilon, and if this threshold is triggered, a design is then given an undesirable score. 
```{r, comment = NA}
singular_check(x = result_a, order = 1)
```
The function returns TRUE if the information matrix calculated from the given design matrix is singular, and FALSE otherwise.

## Fraction of Design Space Plots
After generating designs, a practitioner may want to look at prediction variance qualities to choose a design with low relative prediction variance over the design space. 

We have generated 1000 A and 1000 D optimal designs, each fitting the main effects model with all two-way interactions with 14 experimental runs and 3 experimental factors. Here is how you plot relative prediction variance of the candidate designs we've created for you.
```{r, comment = NA}
set.seed(2199)

# A list of 1000 candidate D optimal designs
optimal_d <- optimalDoe::optimal_D_14_3

# A list of 1000 candidate A optimal designs
optimal_a <- optimalDoe::optimal_A_14_3

# Pulling out the top 2 designs in each list
result_a_14_3 <- lapply(head(optimal_a, 2), `[[`, 1)
result_d_14_3 <- lapply(head(optimal_d, 2), `[[`, 1)

# Combining the top 2 designs from each list into one list
matrix_list <- c(result_a_14_3, result_d_14_3)

# Plot relative prediction variances of the designs
fds_plot(des_list = matrix_list, order = 1)
```


The fds_plot function returns lines corresponding to each design matrix. The labeling of the lines comes from the order of the matrices in the list, i.e. the first element is "Design1" and so forth. 

One desirable trait of an experimental design is that it has lower prediction variance over the design space. If you see one of these design signatures falling below another, the design with the lower signature has more desirable prediction variance qualities.
